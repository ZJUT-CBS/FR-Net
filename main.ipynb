{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82088736",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-27T11:46:39.698392Z",
     "start_time": "2023-07-27T11:46:39.611312Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050390bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-27T11:46:42.518082Z",
     "start_time": "2023-07-27T11:46:39.699780Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch, time, os, shutil\n",
    "import  util\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import Dataset\n",
    "from config import cfg\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from tqdm import tqdm\n",
    "#from loss.md_loss import MultiDomainLoss\n",
    "import torch.nn.functional as F\n",
    "import data_util as du\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb276e54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-27T11:46:42.534093Z",
     "start_time": "2023-07-27T11:46:42.520085Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, criterion, scheduler, train_dataloader):\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "    total = 0\n",
    "    show_bar =False\n",
    "    tbar = tqdm(train_dataloader, disable = not show_bar)\n",
    "    for i, (inputs, target) in enumerate(tbar):      \n",
    "        data = inputs.to(device)\n",
    "        data = data.to(torch.float32)\n",
    "        labelt = target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    " \n",
    "        output = F.sigmoid(output)\n",
    "\n",
    "        loss = criterion(output,labelt.to(torch.float32)) \n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "             \n",
    "    tbar.close()       \n",
    "    for i in range(len(losses)):\n",
    "        total = total + losses[i]\n",
    "        \n",
    "    total /= len(losses)\n",
    "      \n",
    "    return total\n",
    "\n",
    "\n",
    "def val_epoch(model, optimizer, criterion, scheduler, val_dataloader):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    total = 0\n",
    "    show_bar =False\n",
    "    tbar = tqdm(val_dataloader, disable =not show_bar)\n",
    "    for i, (inputs, target) in enumerate(tbar):     \n",
    "        data = inputs.to(device)\n",
    "        data = data.to(torch.float32)\n",
    "        labelt = target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "\n",
    "        output = F.sigmoid(output)\n",
    "\n",
    "        loss = criterion(output,labelt.to(torch.float32)) \n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    tbar.close()\n",
    "    \n",
    "    for i in range(len(losses)):\n",
    "        total = total + losses[i]\n",
    "    total /= len(losses)\n",
    "        \n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4c0393",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-27T11:46:42.549441Z",
     "start_time": "2023-07-27T11:46:42.536096Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    from model import FR_Net\n",
    "    model = FR_Net(input_channel=4,layer=32,kernel_size=3)\n",
    "    return model\n",
    "\n",
    "def get_loss():\n",
    "    from monai.losses import FocalLoss\n",
    "    return FocalLoss(to_onehot_y=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc5d30e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-27T11:46:42.565134Z",
     "start_time": "2023-07-27T11:46:42.551444Z"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    model = get_model()\n",
    "    model = model.to(device)\n",
    "    start_epoch = 1\n",
    "    \n",
    "    train_dataset = Dataset(train=True, seg_len = c.seg_len, fs = c.fs, \n",
    "                                test_idx = test_idx)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=c.batch_size, shuffle=True, num_workers=0)#####\n",
    "    val_dataset = Dataset(train=False, seg_len = c.seg_len, fs = c.fs, \n",
    "                            test_idx = test_idx)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=c.batch_size, num_workers=0)\n",
    "    test_dataset = Dataset(train=False, seg_len = c.seg_len, fs = c.fs, \n",
    "                            test_idx = test_idx)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=c.batch_size, num_workers=0)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=c.lr)\n",
    "    criterion = get_loss()\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=200, gamma=0.2)\n",
    "    \n",
    "    \n",
    "    for epoch in range(start_epoch, c.max_epoch+1):\n",
    "        since = time.time()\n",
    "        train_loss = train_epoch(model, optimizer, criterion, exp_lr_scheduler, train_dataloader)\n",
    "     \n",
    "        val_loss = val_epoch(model, optimizer, criterion, exp_lr_scheduler, val_dataloader)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    pred_label = None\n",
    "\n",
    "    for i, (inputs, target) in enumerate(test_dataloader):     \n",
    "        data = inputs.to(device)\n",
    "        data = data.to(torch.float32)\n",
    "        labelt = target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "     \n",
    "\n",
    "        output = F.sigmoid(output)\n",
    "\n",
    "        output[output >= 0.5] = 1\n",
    "        output[output <  0.5] = 0\n",
    "        output = output.squeeze().detach().cpu().numpy()\n",
    "        if pred_label is None:\n",
    "            pred_label = output.flatten()\n",
    "        else:\n",
    "            pred_label = np.hstack((pred_label, output.flatten()))\n",
    "            \n",
    "    pred_label = pred_label.reshape((len(pred_label)//c.seg_len,1, c.seg_len))\n",
    "    pred_label = du.deframe(pred_label)\n",
    "    \n",
    "    pred_peaks = util.get_peak_from_label(pred_label, fs = c.fs)\n",
    "    fqrs_rpeaks = test_dataset.get_fqrs()\n",
    "    Recall,Precision, F1_score = util.evaluate([fqrs_rpeaks,], [pred_peaks,],fs = c.fs, thr=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862d8b42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-27T11:46:48.624492Z",
     "start_time": "2023-07-27T11:46:42.567136Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "c = cfg()\n",
    "c.max_epoch = 1\n",
    "test_idx = 0\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef95fbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb9360c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee91aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "torch2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
